{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NOTE: 아래는 MNIST 데이터셋을 내려받을 때 \"User-agent\" 관련한 제한을 푸는 코드입니다.\n",
    "#       더 자세한 내용은 https://github.com/pytorch/vision/issues/3497 을 참고해주세요.\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격을 받는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet 모델 정의\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# MNIST 테스트 데이터셋과 데이터로더 선언\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=1, shuffle=True)\n",
    "\n",
    "# 어떤 디바이스를 사용할지 정의\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# 모델 초기화하기\n",
    "model = Net().to(device)\n",
    "\n",
    "# 미리 학습된 모델 읽어오기\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# 모델을 평가 모드로 설정하기. 드롭아웃 레이어들을 위해 사용됨\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGSM 공격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM 공격 코드\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # data_grad 의 요소별 부호 값을 얻어옵니다\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # 입력 이미지의 각 픽셀에 sign_data_grad 를 적용해 작은 변화가 적용된 이미지를 생성합니다\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # 값 범위를 [0,1]로 유지하기 위해 자르기(clipping)를 추가합니다\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # 작은 변화가 적용된 이미지를 리턴합니다\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스팅 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # 정확도 카운터\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # 테스트 셋의 모든 예제에 대해 루프를 돕니다\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # 디바이스(CPU or GPU) 에 데이터와 라벨 값을 보냅니다\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 텐서의 속성 중 requires_grad 를 설정합니다. 공격에서 중요한 부분입니다\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # 데이터를 모델에 통과시킵니다\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # 로그 확률의 최대값을 가지는 인덱스를 얻습니다\n",
    "\n",
    "        # 만약 초기 예측이 틀리면, 공격하지 않도록 하고 계속 진행합니다\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # 손실을 계산합니다\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # 모델의 변화도들을 전부 0으로 설정합니다\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 후방 전달을 통해 모델의 변화도를 계산합니다\n",
    "        loss.backward()\n",
    "\n",
    "        # 변화도 값을 모읍니다\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # FGSM 공격을 호출합니다\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # 작은 변화가 적용된 이미지에 대해 재분류합니다\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # 올바른지 확인합니다\n",
    "        final_pred = output.max(1, keepdim=True)[1] # 로그 확률의 최대값을 가지는 인덱스를 얻습니다\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # 0 엡실론 예제에 대해서 저장합니다\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # 추후 시각화를 위하 다른 예제들을 저장합니다\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # 해당 엡실론에서의 최종 정확도를 계산합니다\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # 정확도와 적대적 예제를 리턴합니다\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# 각 엡실론에 대해 테스트 함수를 실행합니다\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 적대적 예제들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 엡실론에서 적대적 샘플의 몇 가지 예를 도식화합니다\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
